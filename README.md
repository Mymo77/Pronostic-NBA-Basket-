# Mod√©lisation de Pr√©diction NBA üèÄ ## Objectif du Projet L'objectif de ce projet est de concevoir un **mod√®le de machine learning** capable de pr√©dire l‚Äôissue des matchs de la NBA en se basant sur les statistiques des feuilles de match (*boxscores*) des 10 derni√®res saisons. Pour atteindre cet objectif, j'ai : - D√©velopp√© un outil de **web-scraping personnalis√©** pour collecter les donn√©es de plus de 12 000 matchs. - Agr√©g√© et pr√©par√© plusieurs jeux de donn√©es pour la mod√©lisation. - Test√© et it√©r√© sur diff√©rents algorithmes pour optimiser la pr√©cision des pr√©dictions. --- ## Partenaire / Stakeholder Le projet a √©t√© r√©alis√© pour **Stat-Ball**, un site d‚Äôactualit√©s sportives et de divertissement. La plateforme souhaite lancer des comp√©titions de pronostics et a besoin d‚Äôun **mod√®le interne robuste** servant de r√©f√©rence (*benchmark*) pour les utilisateurs. --- ## R√©sum√© du Projet - Le meilleur mod√®le obtenu est un **Gaussian Naive-Bayes (GNB)** avec r√©duction de dimensionnalit√© via **PCA**. - Entra√Æn√© sur les statistiques moyennes des √©quipes sur les 20 derniers matchs. - **Pr√©cision obtenue : 63,5 %**, l√©g√®rement en dessous du seuil cible de 68 % (victoire moyenne des favoris en NBA). - Prochaine √©tape : int√©grer les **donn√©es joueurs et statistiques avanc√©es** pour am√©liorer la pr√©cision. --- ## Table des Mati√®res 1. [Aper√ßu des Donn√©es](#aper√ßu-des-donn√©es) 2. [Mod√©lisation](#mod√©lisation) 3. [R√©sultats](#r√©sultats) 4. [Prochaines √âtapes](#prochaines-√©tapes) 5. [Technologies utilis√©es](#technologies-utilis√©es) --- ## Aper√ßu des Donn√©es - Le dataset final contient des statistiques agr√©g√©es par √©quipe sur des fen√™tres de **10, 20 et 30 matchs**. - La distribution des donn√©es est **approximativement normale**, limitant le besoin de pr√©traitement lourd. ### Collecte des donn√©es - Extraction des donn√©es de saison r√©guli√®re des **10 derni√®res ann√©es** via [basketball-reference.com](https://www.basketball-reference.com). - Base SQLite structur√©e avec **3 tables** : informations de match, statistiques joueurs, statistiques √©quipes. - **341 669 observations** et **46 colonnes** couvrant 11 979 matchs. ### Agr√©gation des donn√©es - Une moyenne sur 20 matchs offre un bon compromis entre **stabilit√© et r√©activit√© aux performances r√©centes**. - Limites : pas de donn√©es de suivi des joueurs (*player tracking*) et agr√©gation bas√©e sur l‚Äô√©quipe plut√¥t que sur les joueurs individuels. --- ## Mod√©lisation Algorithmes test√©s : - R√©gression Logistique - K-Nearest Neighbors (KNN) - Random Forest (RF) - Gaussian Naive-Bayes (GNB) - Support Vector Classifier (SVC) - R√©seaux de Neurones (NN) **Mod√®le de r√©f√©rence (Baseline)** : pr√©dire syst√©matiquement la victoire de l‚Äô√©quipe √† domicile (~57,2 % de victoires √† domicile). Traditionnellement, le taux de surprises en NBA se situe entre 28 et 32 ‚Äã‚Äã%, ce qui signifie que l'√©quipe favorite l'emporte dans 68 √† 72 % des cas. De ce fait, il est tr√®s difficile de cr√©er un mod√®le dont la pr√©cision d√©passe cette fourchette. Compte tenu des limitations des donn√©es utilis√©es, j'esp√®re atteindre une pr√©cision proche du seuil de 68 %. ### Analyse des erreurs J'ai commenc√© par tester les donn√©es √† quatre facteurs en utilisant les moyennes des 10, 20 et 30 derniers matchs. Les donn√©es agr√©g√©es sur 10 matchs ont donn√© des r√©sultats inf√©rieurs aux attentes, tandis que celles sur 20 et 30 matchs pr√©sentaient une pr√©cision moyenne similaire pour tous les mod√®les. Finalement, j'ai d√©cid√© de me concentrer sur l'agr√©gation sur 20 matchs lors des tests sur l'ensemble des donn√©es, incluant toutes les statistiques de feuille de match. J'ai √©galement √©valu√© l'erreur du mod√®le plus en d√©tail. L'utilisation de donn√©es agr√©g√©es par √©quipe m'indique que les mod√®les ne peuvent pas int√©grer rapidement les changements d'effectif, principalement dus √† quelques facteurs : blessures, transferts, agents libres, draft Mon hypoth√®se √©tait que les mod√®les pr√©senteraient moins d'erreurs en seconde partie de saison, du fait de la diminution des changements d'effectifs. En NBA, une fois la date limite des transferts pass√©e, les effectifs restent globalement stables, hormis les blessures et quelques signatures ponctuelles. En revanche, le d√©but de saison est marqu√© par une grande incertitude, car c'est durant l'intersaison que l'on observe la majorit√© des changements d'effectifs. De plus, comme les donn√©es agr√©g√©es par √©quipe ne sont pas r√©initialis√©es d'une saison √† l'autre, les mod√®les utilisent des donn√©es report√©es de la fin de la saison pr√©c√©dente, m√™me si les effectifs peuvent √™tre totalement diff√©rents. J'ai analys√© les statistiques d'erreur en calculant l'erreur moyenne sur l'ensemble des saisons, puis en r√©partissant le nombre d'erreurs par trimestre. Ce calcul a √©t√© effectu√© √† partir des donn√©es agr√©g√©es sur 10 matchs, prenant en compte quatre facteurs. <img width="1324" height="873" alt="model_error_per_season_quarter" src="https://github.com/user-attachments/assets/f7458dd0-e3b0-444b-910a-2032fa6f1761" /> Il est clair que les mod√®les se comportent de mani√®re tr√®s similaire, non seulement en termes de pr√©cision globale, mais aussi en ce qui concerne la distribution des erreurs au cours d'une saison. Mon hypoth√®se selon laquelle la seconde moiti√© de chaque saison serait moins sujette aux erreurs semble plausible, mais la similarit√© entre les mod√®les sugg√®re √©galement que les donn√©es ne contiennent pas suffisamment d'informations pour les diff√©rencier. J'ai √©galement examin√© l'erreur moyenne du mod√®le par saison afin de d√©celer d'√©ventuelles valeurs aberrantes. √âtant donn√© que certaines saisons comptaient moins de matchs que d'autres, j'ai ajust√© les r√©sultats pour qu'ils repr√©sentent l'erreur moyenne par match pour chaque saison. <img width="1320" height="853" alt="average_error_per_game" src="https://github.com/user-attachments/assets/70b6729f-5219-4026-8652-7dd9de1194a1" /> Chaque saison a enregistr√© environ 0,35 √† 0,40 erreur par match, ce qui signifie que pour 10 matchs par saison, les mod√®les ont commis en moyenne 3,5 √† 4 erreurs. Cela correspond √† une pr√©cision moyenne des mod√®les d'environ 60 %. Apr√®s avoir test√© les quatre jeux de donn√©es factoriels, qui ont atteint une pr√©cision moyenne d'environ 61 √† 62 %, j'ai √©galement utilis√© les jeux de donn√©es PCA et les jeux de donn√©es complets. Une analyse d√©taill√©e des r√©sultats de mod√©lisation est disponible dans la section ¬´ R√©sultats ¬ª, mais aucun des mod√®les n'a atteint l'objectif de 68 %. Un mod√®le d'ensemble avait √©galement peu de chances d'atteindre cet objectif, car les mod√®les individuels pr√©sentaient des performances tr√®s similaires. --- ## R√©sultats - **Gaussian Naive-Bayes (PCA)** : 63,5 % de pr√©cision - **Random Forest (Feature Selection)** : 62,8 % - **R√©gression Logistique** : 62,1 % **Observations** : - Les variables les plus importantes : efficacit√© au tir, diff√©rentiel de rebonds, statistiques d√©fensives. - Graphiques recommand√©s : matrice de confusion, importance des variables, distribution des erreurs par quart de saison. ## Conclusion Ce projet visait √† mieux comprendre les dynamiques de victoire dans la NBA en s‚Äôappuyant sur les performances statistiques pass√©es des √©quipes. En mod√©lisant l‚Äôissue d‚Äôun match via diff√©rentes techniques de machine learning (r√©gression logistique, SVM, random forest, Na√Øve Bayes, etc.), notre objectif √©tait d‚Äôidentifier les facteurs les plus d√©terminants dans la construction d‚Äôune victoire. Parmi les diff√©rents mod√®les test√©s, c‚Äôest le Na√Øve Bayes avec r√©duction de dimension par ACP (GNB_PCA) qui a obtenu les meilleurs r√©sultats, atteignant une pr√©cision de 63,5‚ÄØ%. Cela constitue une am√©lioration significative par rapport √† la baseline de 57,2‚ÄØ%, bas√©e sur l‚Äôavantage √† domicile. Ce r√©sultat montre que les mod√®les d‚Äôapprentissage automatique sont capables de capter des dynamiques de performance au-del√† des simples effets contextuels. Nos analyses r√©v√®lent que certains indicateurs statistiques sont particuli√®rement li√©s √† la victoire, notamment : eFG% (effective field goal percentage) et TS% (true shooting percentage) : deux mesures cl√©s de l‚Äôefficacit√© offensive, qui int√®grent la valeur des tirs √† trois points et l‚Äôefficacit√© aux lancers francs. TRB% (taux de rebonds totaux), FG% (pourcentage de r√©ussite aux tirs) et le nombre de points marqu√©s (PTS), qui traduisent une ma√Ætrise du rythme de jeu et une capacit√© √† concr√©tiser les possessions. √Ä l‚Äôinverse, des statistiques plus traditionnelles comme le nombre de passes d√©cisives (AST), les interceptions (STL) ou encore les fautes ont un poids plus marginal dans la pr√©diction. Ces r√©sultats nous permettent de mieux cerner ce qui fait la diff√©rence sur le terrain : l‚Äôefficacit√© offensive et le contr√¥le du rebond apparaissent comme les leviers essentiels de la performance. Cela peut en partie expliquer pourquoi certaines √©quipes r√©ussissent √† maintenir un haut niveau de succ√®s sur plusieurs saisons : elles ma√Ætrisent ces fondamentaux de mani√®re plus stable, ind√©pendamment des contraintes impos√©es par la ligue. La domination r√©sulte donc d‚Äôune optimisation constante des √©l√©ments les plus d√©cisifs du jeu d√©crit plus haut. <img width="863" height="545" alt="feat_imp_RF_best" src="https://github.com/user-attachments/assets/9a34546a-4815-4e48-88b2-e16c66b3b312" /> --- ## Prochaines √âtapes - **Agr√©gation par joueur** : int√©grer les stats individuelles pour ajuster la force d‚Äôune √©quipe. - **Ing√©nierie de caract√©ristiques avanc√©es** : metrics comme PIE (Player Impact Estimate) ou BPM (Box Plus/Minus). - **Mod√®les d‚Äôensemble** : combiner plusieurs mod√®les (Boosting/Stacking) pour am√©liorer la pr√©cision. - **Donn√©es contextuelles** : fatigue, matchs cons√©cutifs, distances de d√©placement. --- ## Technologies utilis√©es - **Python** : Pandas, Scikit-Learn, BeautifulSoup, Selenium - **SQL** : SQLite - **Analyse de donn√©es** : PCA, Feature Selection - **Visualisation** : Matplotlib, Seaborn voila re ecrit en mieux mais je veux la meme chose
