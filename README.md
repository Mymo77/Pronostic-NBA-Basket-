# Mod√©lisation de Pr√©diction NBA üèÄ

## Objectif du Projet
L'objectif de ce projet est de concevoir un **mod√®le de machine learning** capable de pr√©dire l‚Äôissue des matchs de la NBA en se basant sur les statistiques des feuilles de match (*boxscores*) des 10 derni√®res saisons.

Pour atteindre cet objectif, j'ai :  
- D√©velopp√© un outil de **web-scraping personnalis√©** pour collecter les donn√©es de plus de 12 000 matchs.  
- Agr√©g√© et pr√©par√© plusieurs jeux de donn√©es pour la mod√©lisation.  
- Test√© et it√©r√© sur diff√©rents algorithmes pour optimiser la pr√©cision des pr√©dictions.  

---

## Partenaire / Stakeholder
Le projet a √©t√© r√©alis√© pour **Stat-Ball**, un site d‚Äôactualit√©s sportives et de divertissement.  
La plateforme souhaite lancer des comp√©titions de pronostics et a besoin d‚Äôun **mod√®le interne robuste** servant de r√©f√©rence (*benchmark*) pour les utilisateurs.

---

## R√©sum√© du Projet
- Le meilleur mod√®le obtenu est un **Gaussian Naive-Bayes (GNB)** avec r√©duction de dimensionnalit√© via **PCA**.  
- Entra√Æn√© sur les statistiques moyennes des √©quipes sur les 20 derniers matchs.  
- **Pr√©cision obtenue : 63,5 %**, l√©g√®rement en dessous du seuil cible de 68 % (victoire moyenne des favoris en NBA).  
- Prochaine √©tape : int√©grer les **donn√©es joueurs et statistiques avanc√©es** pour am√©liorer la pr√©cision.  

---

## Table des Mati√®res
1. [Aper√ßu des Donn√©es](#aper√ßu-des-donn√©es)  
2. [Mod√©lisation](#mod√©lisation)  
3. [R√©sultats](#r√©sultats)  
4. [Prochaines √âtapes](#prochaines-√©tapes)  
5. [Technologies utilis√©es](#technologies-utilis√©es)  

---

## Aper√ßu des Donn√©es
- Le dataset final contient des statistiques agr√©g√©es par √©quipe sur des fen√™tres de **10, 20 et 30 matchs**.  
- La distribution des donn√©es est **approximativement normale**, limitant le besoin de pr√©traitement lourd.  

### Collecte des donn√©es
- Extraction des donn√©es de saison r√©guli√®re des **10 derni√®res ann√©es** via [basketball-reference.com](https://www.basketball-reference.com).  
- Base SQLite structur√©e avec **3 tables** : informations de match, statistiques joueurs, statistiques √©quipes.  
- **341 669 observations** et **46 colonnes** couvrant 11 979 matchs.  

### Agr√©gation des donn√©es
- Une moyenne sur 20 matchs offre un bon compromis entre **stabilit√© et r√©activit√© aux performances r√©centes**.  
- Limites : pas de donn√©es de suivi des joueurs (*player tracking*) et agr√©gation bas√©e sur l‚Äô√©quipe plut√¥t que sur les joueurs individuels.  

---

## Mod√©lisation
Algorithmes test√©s :  
- R√©gression Logistique  
- K-Nearest Neighbors (KNN)  
- Random Forest (RF)  
- Gaussian Naive-Bayes (GNB)  
- Support Vector Classifier (SVC)  
- R√©seaux de Neurones (NN)  

**Mod√®le de r√©f√©rence (Baseline)** : pr√©dire syst√©matiquement la victoire de l‚Äô√©quipe √† domicile (~57,2 % de victoires √† domicile). 
Traditionnellement, le taux de surprises en NBA se situe entre 28 et 32 ‚Äã‚Äã%, ce qui signifie que l'√©quipe favorite l'emporte dans 68 √† 72 % des cas. De ce fait, il est tr√®s difficile de cr√©er un mod√®le dont la pr√©cision d√©passe cette fourchette. Compte tenu des limitations des donn√©es utilis√©es, j'esp√®re atteindre une pr√©cision proche du seuil de 68 %.

### Analyse des erreurs
J'ai commenc√© par tester les donn√©es √† quatre facteurs en utilisant les moyennes des 10, 20 et 30 derniers matchs. Les donn√©es agr√©g√©es sur 10 matchs ont donn√© des r√©sultats inf√©rieurs aux attentes, tandis que celles sur 20 et 30 matchs pr√©sentaient une pr√©cision moyenne similaire pour tous les mod√®les. Finalement, j'ai d√©cid√© de me concentrer sur l'agr√©gation sur 20 matchs lors des tests sur l'ensemble des donn√©es, incluant toutes les statistiques de feuille de match.

J'ai √©galement √©valu√© l'erreur du mod√®le plus en d√©tail. L'utilisation de donn√©es agr√©g√©es par √©quipe m'indique que les mod√®les ne peuvent pas int√©grer rapidement les changements d'effectif, principalement dus √† quelques facteurs :

blessures
transferts
agents libres
draft

Mon hypoth√®se √©tait que les mod√®les pr√©senteraient moins d'erreurs en seconde partie de saison, du fait de la diminution des changements d'effectifs. En NBA, une fois la date limite des transferts pass√©e, les effectifs restent globalement stables, hormis les blessures et quelques signatures ponctuelles. En revanche, le d√©but de saison est marqu√© par une grande incertitude, car c'est durant l'intersaison que l'on observe la majorit√© des changements d'effectifs. De plus, comme les donn√©es agr√©g√©es par √©quipe ne sont pas r√©initialis√©es d'une saison √† l'autre, les mod√®les utilisent des donn√©es report√©es de la fin de la saison pr√©c√©dente, m√™me si les effectifs peuvent √™tre totalement diff√©rents. J'ai analys√© les statistiques d'erreur en calculant l'erreur moyenne sur l'ensemble des saisons, puis en r√©partissant le nombre d'erreurs par trimestre. Ce calcul a √©t√© effectu√© √† partir des donn√©es agr√©g√©es sur 10 matchs, prenant en compte quatre facteurs.


---

## R√©sultats
- **Gaussian Naive-Bayes (PCA)** : 63,5 % de pr√©cision  
- **Random Forest (Feature Selection)** : 62,8 %  
- **R√©gression Logistique** : 62,1 %  

**Observations** :  
- Les variables les plus importantes : efficacit√© au tir, diff√©rentiel de rebonds, statistiques d√©fensives.  
- Graphiques recommand√©s : matrice de confusion, importance des variables, distribution des erreurs par quart de saison.  

---

## Prochaines √âtapes
- **Agr√©gation par joueur** : int√©grer les stats individuelles pour ajuster la force d‚Äôune √©quipe.  
- **Ing√©nierie de caract√©ristiques avanc√©es** : metrics comme PIE (Player Impact Estimate) ou BPM (Box Plus/Minus).  
- **Mod√®les d‚Äôensemble** : combiner plusieurs mod√®les (Boosting/Stacking) pour am√©liorer la pr√©cision.  
- **Donn√©es contextuelles** : fatigue, matchs cons√©cutifs, distances de d√©placement.  

---

## Technologies utilis√©es
- **Python** : Pandas, Scikit-Learn, BeautifulSoup, Selenium  
- **SQL** : SQLite  
- **Analyse de donn√©es** : PCA, Feature Selection  
- **Visualisation** : Matplotlib, Seaborn
