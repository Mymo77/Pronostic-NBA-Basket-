# Mod√©lisation de Pr√©diction NBA üèÄ

## Objectif du Projet
L'objectif de ce projet est de concevoir un **mod√®le de machine learning** capable de pr√©dire l‚Äôissue des matchs de la NBA en se basant sur les statistiques des feuilles de match (*boxscores*) des 10 derni√®res saisons.

Pour atteindre cet objectif, j'ai :  
- D√©velopp√© un outil de **web-scraping personnalis√©** pour collecter les donn√©es de plus de 12 000 matchs.  
- Agr√©g√© et pr√©par√© plusieurs jeux de donn√©es pour la mod√©lisation.  
- Test√© et it√©r√© sur diff√©rents algorithmes pour optimiser la pr√©cision des pr√©dictions.  

---

## R√©sum√© du Projet
- Le meilleur mod√®le obtenu est un **Gaussian Naive-Bayes (GNB)** avec r√©duction de dimensionnalit√© via **PCA**.  
- Entra√Æn√© sur les statistiques moyennes des √©quipes sur les 20 derniers matchs.  
- **Pr√©cision obtenue : 63,5 %**, l√©g√®rement en dessous du seuil cible de 68 % (victoire moyenne des favoris en NBA).  
- Prochaine √©tape : int√©grer les **donn√©es joueurs et statistiques avanc√©es** pour am√©liorer la pr√©cision.  

---

## Table des Mati√®res
1. [Aper√ßu des Donn√©es](#aper√ßu-des-donn√©es)  
2. [Mod√©lisation](#mod√©lisation)  
3. [R√©sultats](#r√©sultats)  
4. [Conclusion](#conclusion)  
5. [Prochaines √âtapes](#prochaines-√©tapes)  
6. [Technologies utilis√©es](#technologies-utilis√©es)  

---

## Aper√ßu des Donn√©es
- Le dataset final contient des statistiques agr√©g√©es par √©quipe sur des fen√™tres de **10, 20 et 30 matchs**.  
- La distribution des donn√©es est **approximativement normale**, limitant le besoin de pr√©traitement lourd.  

### Collecte des donn√©es
- Extraction des donn√©es de saison r√©guli√®re des **10 derni√®res ann√©es** via [basketball-reference.com](https://www.basketball-reference.com).  
- Base SQLite structur√©e avec **3 tables** : informations de match, statistiques joueurs, statistiques √©quipes.  
- **341 669 observations** et **46 colonnes** couvrant 11 979 matchs.  

### Agr√©gation des donn√©es
- Une moyenne sur 20 matchs offre un bon compromis entre **stabilit√© et r√©activit√© aux performances r√©centes**.  
- Limites : pas de donn√©es de suivi des joueurs (*player tracking*) et agr√©gation bas√©e sur l‚Äô√©quipe plut√¥t que sur les joueurs individuels.  

---

## Mod√©lisation
Algorithmes test√©s :  
- R√©gression Logistique  
- K-Nearest Neighbors (KNN)  
- Random Forest (RF)  
- Gaussian Naive-Bayes (GNB)  
- Support Vector Classifier (SVC)  
- R√©seaux de Neurones (NN)  

**Mod√®le de r√©f√©rence (Baseline)** : pr√©dire syst√©matiquement la victoire de l‚Äô√©quipe √† domicile (~57,2 % de victoires √† domicile).  

Traditionnellement, le taux de surprises en NBA se situe entre 28 et 32‚ÄØ%, ce qui signifie que l'√©quipe favorite l'emporte dans 68 √† 72‚ÄØ% des cas. Compte tenu des limitations des donn√©es utilis√©es, l'objectif √©tait d'approcher cette pr√©cision.

### Analyse des erreurs
- Les mod√®les pr√©sentent plus d‚Äôerreurs en d√©but de saison √† cause des changements d‚Äôeffectifs : blessures, transferts, agents libres, draft.  
- Les erreurs sont moins fr√©quentes en seconde partie de saison, quand les √©quipes sont stables.  
- L‚Äôanalyse de l‚Äôerreur moyenne par saison et par quart de saison a montr√© une pr√©cision moyenne d‚Äôenviron 60‚ÄØ%.  

#### Distribution des erreurs par quart de saison
<img width="1324" height="873" alt="model_error_per_season_quarter" src="https://github.com/user-attachments/assets/d0ad58ba-eeff-4793-b62a-c13549161aaa" />

#### Erreur moyenne par match
<img width="1320" height="853" alt="average_error_per_game" src="https://github.com/user-attachments/assets/d1c9da92-2e73-4836-b1c5-f2d6f51acb24" />



---

## R√©sultats
- **Gaussian Naive-Bayes (PCA)** : 63,5 % de pr√©cision  
- **Random Forest (Feature Selection)** : 62,8 %  
- **R√©gression Logistique** : 62,1 %  

**Observations** :  
- Les variables les plus importantes : efficacit√© au tir (eFG%, TS%), diff√©rentiel de rebonds (TRB%), points marqu√©s (PTS), statistiques d√©fensives.  
- Graphiques recommand√©s : matrice de confusion, importance des variables, distribution des erreurs par quart de saison.  

<img width="863" height="545" alt="feat_imp_RF_best" src="https://github.com/user-attachments/assets/31372992-158e-4097-9492-622b647571c0" />


---

## Conclusion
Ce projet a permis de mieux comprendre les dynamiques de victoire en NBA √† partir des performances pass√©es des √©quipes.  
- Le **GNB avec PCA** a √©t√© le mod√®le le plus performant (63,5‚ÄØ%), sup√©rieur √† la baseline de 57,2‚ÄØ%.  
- Les indicateurs les plus d√©terminants sont l‚Äôefficacit√© offensive et le contr√¥le du rebond.  
- Ces r√©sultats montrent que le machine learning peut capturer des dynamiques au-del√† des simples effets contextuels.

---

## Prochaines √âtapes
- **Agr√©gation par joueur** : int√©grer les stats individuelles pour ajuster la force d‚Äôune √©quipe.  
- **Ing√©nierie de caract√©ristiques avanc√©es** : metrics comme PIE ou BPM.  
- **Mod√®les d‚Äôensemble** : combiner plusieurs mod√®les (Boosting/Stacking).  
- **Donn√©es contextuelles** : fatigue, matchs cons√©cutifs, distances de d√©placement.  

---

## Technologies utilis√©es
- **Python** : Pandas, Scikit-Learn, BeautifulSoup, Selenium  
- **SQL** : SQLite  
- **Analyse de donn√©es** : PCA, Feature Selection  
- **Visualisation** : Matplotlib, Seaborn
